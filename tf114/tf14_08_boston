from inspect import Parameter
from sklearn.datasets import load_boston
from sklearn.model_selection import GridSearchCV,KFold,StratifiedKFold,train_test_split
from sklearn.preprocessing import MinMaxScaler,StandardScaler
from xgboost import XGBClassifier,XGBRegressor
import time
import numpy as np
from sklearn.feature_selection import SelectFromModel
from sklearn.metrics import r2_score
from bayes_opt import BayesianOptimization
from xgboost import XGBRegressor
#1.data
datasets = load_boston()
x_data = datasets.data
y_data = datasets.target.reshape(-1,1)
print(x_data.shape, y_data.shape)
x_train, x_test, y_train, y_test = train_test_split(x_data,y_data,train_size=0.8,random_state=234)
import tensorflow as tf
x = tf.placeholder(tf.float32,shape=[None,13])
w = tf.Variable(tf.random_normal([13,1]))
b = tf.Variable(tf.random_normal([1,1]))
y = tf.placeholder(tf.float32,shape=[None,1])

hypothesis = tf.matmul(x,w)+b
loss = tf.reduce_mean(tf.square(hypothesis-y))
train = tf.train.GradientDescentOptimizer(learning_rate=0.0001).minimize(loss)

with tf.compat.v1.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for i in range(201):
        h_val = sess.run(hypothesis, feed_dict={x:x_train,y:y_train})
        if i % 20 == 0:
            print(i, h_val)
    pred = sess.run(hypothesis, feed_dict={x:x_test})
    print(y_test)
    print(pred)
    print(r2_score(y_test,pred))
# xgb
# time 0.06499075889587402
# score -3.978463050927994

# xgb bagging
# time 86.17413973808289
# score 0.8960392970522392
# 0.8960392970522392

# polynomial
# 0.8559369643998214